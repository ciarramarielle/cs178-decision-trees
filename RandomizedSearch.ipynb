{
 "metadata": {
  "name": "",
  "signature": "sha256:b1d5c72b2e6deb4de304380884f2ee3d0e051aa1264b06b9d141b0a409fbd013"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(__doc__)\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from time import time\n",
      "from operator import itemgetter\n",
      "from scipy.stats import randint as sp_randint\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
      "from sklearn.datasets import load_digits\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "\n",
      "# get some data\n",
      "'''\n",
      "digits = load_digits()\n",
      "X, y = digits.data, digits.target\n",
      "'''\n",
      "\n",
      "#data = np.genfromtxt(\"/Users/Mahsa/Documents/Irvine/Winter2015/compsci178/hw/project/iris.txt\",delimiter=None) \n",
      "X = np.genfromtxt(\"/Users/Mahsa/Documents/Irvine/Winter2015/compsci178/hw/hw2/HW2c/data/kaggle.X1.train.txt\",delimiter=',') \n",
      "y = np.genfromtxt(\"/Users/Mahsa/Documents/Irvine/Winter2015/compsci178/hw/hw2/HW2c/data/kaggle.Y.train.txt\",delimiter=',') \n",
      "\n",
      "'''\n",
      "X = data[:,0:-1] \n",
      "y = data[:,-1]\n",
      "'''\n",
      "'''\n",
      "Xt,Xv,Yt,Yv = ml.splitData(X,Y,0.75) # split data set 75/25\n",
      "Yv = Yv[:,np.newaxis]\n",
      "'''\n",
      "\n",
      "# build a classifier\n",
      "#clf = ExtraTreesRegressor(n_estimators=20)\n",
      "clf = ExtraTreesRegressor()\n",
      "\n",
      "\n",
      "# Utility function to report best scores\n",
      "def report(grid_scores, n_top=3):\n",
      "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
      "    for i, score in enumerate(top_scores):\n",
      "        print(\"Model with rank: {0}\".format(i + 1))\n",
      "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
      "              score.mean_validation_score,\n",
      "              np.std(score.cv_validation_scores)))\n",
      "        print(\"Parameters: {0}\".format(score.parameters))\n",
      "        print(\"\")\n",
      "\n",
      "\n",
      "# specify parameters and distributions to sample from\n",
      "param_dist = {\"max_depth\": [20, None],\n",
      "              \"max_features\": sp_randint(1, 91),\n",
      "              #\"min_samples_split\": sp_randint(1, 11),\n",
      "              #\"min_samples_leaf\": sp_randint(1, 11),\n",
      "              \"bootstrap\": [True, False]}\n",
      "             # \"criterion\": [\"gini\"]}\n",
      "\n",
      "# run randomized search\n",
      "n_iter_search = 20\n",
      "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
      "                                   n_iter=n_iter_search)\n",
      "\n",
      "start = time()\n",
      "random_search.fit(X, y)\n",
      "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
      "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
      "report(random_search.grid_scores_)\n",
      "\n",
      "'''\n",
      "# use a full grid over all parameters\n",
      "param_grid = {\"max_depth\": [3, None],\n",
      "              \"max_features\": [1, 3, 10],\n",
      "              \"min_samples_split\": [1, 3, 10],\n",
      "              \"min_samples_leaf\": [1, 3, 10],\n",
      "              \"bootstrap\": [True, False],\n",
      "              \"criterion\": [\"gini\", \"entropy\"]}\n",
      "\n",
      "# run grid search\n",
      "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
      "start = time()\n",
      "grid_search.fit(X, y)\n",
      "\n",
      "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
      "      % (time() - start, len(grid_search.grid_scores_)))\n",
      "report(grid_search.grid_scores_)\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Xt,Xv,Yt,Yv = ml.splitData(X,Y,0.75) # split data set 75/25\n",
        "Yv = Yv[:,np.newaxis]\n",
        "\n",
        "RandomizedSearchCV took 354.86 seconds for 20 candidates parameter settings."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model with rank: 1\n",
        "Mean validation score: 0.429 (std: 0.006)\n",
        "Parameters: {'max_features': 41, 'bootstrap': False, 'max_depth': 20}\n",
        "\n",
        "Model with rank: 2\n",
        "Mean validation score: 0.429 (std: 0.008)\n",
        "Parameters: {'max_features': 74, 'bootstrap': False, 'max_depth': 20}\n",
        "\n",
        "Model with rank: 3\n",
        "Mean validation score: 0.428 (std: 0.005)\n",
        "Parameters: {'max_features': 84, 'bootstrap': False, 'max_depth': None}\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "'\\n# use a full grid over all parameters\\nparam_grid = {\"max_depth\": [3, None],\\n              \"max_features\": [1, 3, 10],\\n              \"min_samples_split\": [1, 3, 10],\\n              \"min_samples_leaf\": [1, 3, 10],\\n              \"bootstrap\": [True, False],\\n              \"criterion\": [\"gini\", \"entropy\"]}\\n\\n# run grid search\\ngrid_search = GridSearchCV(clf, param_grid=param_grid)\\nstart = time()\\ngrid_search.fit(X, y)\\n\\nprint(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\\n      % (time() - start, len(grid_search.grid_scores_)))\\nreport(grid_search.grid_scores_)\\n'"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}